import re, argparse

parser = argparse.ArgumentParser(description="This script extracts insertions sequences assembled by SPades.")
parser.add_argument("-transcript_fasta", "--fasta", help="Path to transcript.fasta file created by SPades")
parser.add_argument("-sam_file", "--sam", help="Path to file sam containing aligned consensus sequences")
parser.add_argument("-output_file", "--out", help="Path to the output file, which contains the extracted insertion sequences")
parser.add_argument("-maximum_insertion_size", "--max_size", help="Maximum permitted size of insertions.", default=8000)
args = parser.parse_args()

fasta_path = args.fasta
sam_path = args.sam
output_path = args.out
max_size = int(args.max_size)

# Store lines in list for higher efficiency
nodes_seqs = {}
first_node = True

# Open transcript.fasta file generated by SPAdes and extract nodes
with open(fasta_path, "r") as file:
    for line in file:
        line = line.strip()
        if line.startswith(">"):
            node = line[1:]
            nodes_seqs[node] = ""
        else:
            nodes_seqs[node] += line
file.close()

consensus_data = {}

# Open sam file and extract matching reads/consensus sequences
with open(sam_path, "r") as file:
    
    for line in file:
        line = line.strip()
        
        # Skip all header lines
        if line.startswith("@") or line == "":
            continue
        
        line_splitted = line.split("\t")
        
        # Extract ID and check if this is a start- or end match (-1 := Start; 1 := End)
        cons = line_splitted[0]
        cons_splitted = cons.split("_")
        insertion = "-".join(cons_splitted[:2])
        
        if insertion not in consensus_data.keys():
            consensus_data[insertion] = {}
        
        direction = cons_splitted[2]
        
        # Get strand of alignment (1 := Forward strand; -1 := Reverse strand; 0 := No matches found)
        tmp_type = line_splitted[1]
        if tmp_type == "0" or tmp_type == "256":
            alg_type = "Forward"
            
        elif tmp_type == "16" or tmp_type == "272" or tmp_type == "2064":
            alg_type = "Reverse"
            if direction == "START":
                direction = "END"
            else:
                direction = "START"
        elif tmp_type == "4":
            continue
        
        if direction not in consensus_data[insertion].keys():
            consensus_data[insertion][direction] = []
        
        # Get node of assembled sequences, where consensus sequence has matched
        node_match = line_splitted[2]
        # Get start postion of matches
        start_pos = int(line_splitted[3])
        # Look for clippings/mismatches
        cigar = line_splitted[5]
        
        # Store everything in dictionary
        consensus_data[insertion][direction].append([node_match, direction, start_pos, alg_type, cigar])
file.close()

# There can/are mutliple start- and end matches in different nodes for the consensus sequences. Therefore we have to identify the best match via 2 layers/analysis steps:
# If no matches fullfill the criterias for a certain layer, select all nodes for the next layer
# 1. Take only those matches, where start- and end consensus sequence is in the same node and are on same strands
# 2. Take only those matches that have the most matching bases in the cigar string

# This is used for the 1st layer and stores PAIRS of start- and end matches
node_matches = {}

#### 1st layer ####
for insertion in consensus_data.keys():
    
    # Initialize for every insertion a list, where the pairs will be stored in
    node_matches[insertion] = []
    
    # Iterate over all start- and end matches and add/select those, whose node and strand match
    if "START" in consensus_data[insertion].keys() and "END" in consensus_data[insertion].keys():
        for match_start in consensus_data[insertion]["START"]:
            node_start, alg_type_start = match_start[0], match_start[3]
            for match_end in consensus_data[insertion]["END"]:
                node_end, alg_type_end = match_end[0], match_end[3]
                if node_start == node_end and alg_type_start == alg_type_end:
                    # Check if (for what ever reason) that the start match appears before the end match -> If not, change!
                    if match_start[2] <= match_end[2]:
                        node_matches[insertion].append([match_start, match_end])
                    else:
                        match_start[1] = "END"
                        match_end[1] = "START"
                        node_matches[insertion].append([match_end, match_start])
    
    # If there are no two start- and end matches sharing the same node and strand, assign each start-/end match the node-end/-start as the end-/start position of the assembled sequence
    if len(node_matches[insertion]) == 0:
        if "START" in consensus_data[insertion].keys():
            for match_start in consensus_data[insertion]["START"]:
                node_start, alg_type_start = match_start[0], match_start[3]
                # If we want to create a synthetic end match for a start match in the same node on the same strand, we have to:
                # Assign it the same node, the "END" parameter, the start position (which is simply the end of the node), the same alignment type and an empty cigar string
                node_matches[insertion].append([match_start, [node_start, "END", len(nodes_seqs[node_start]), alg_type_start, ""]])
        # Same story for end matches (-> assign them a synthetic start match) [start_match, end_match]
        if "END" in consensus_data[insertion].keys():
            for match_end in consensus_data[insertion]["END"]:
                node_end, alg_type_end = match_end[0], match_end[3]
                node_matches[insertion].append([[node_end, "START", 1, alg_type_end, ""], match_end])
# This used for the 2nd layer
cigar_matches = {}

# This funcntion extracts the number of matching nucleotides from a cigar string, e.g. "32" from "7H32M"
def get_matching_number(cigar):
    
    # If cigar string is empty (only occurs for synthetic matches), we obviously have no matching nucleotides
    if cigar == "":
        return 0
    
    # The regular expression to extract the "M-Number"
    reg = re.search(r'(\d+)M', cigar)
    # If the "M-Number" is contained in the cigar string, return a percentage of matching nucleotdies
    if reg:
        return int(reg.group(1))
    # If not, return -1 suggesting an error (I don't know if this case can actually happen? -> Let's assure it nevertheless)
    else:
        return -1

# This function calculates and returns the length of a cigar string/consensus sequence
def get_length_of_consensus(cigar):
    
    # If cigar string is empty (only occurs for synthetic matches), the length is obvioulsy 0
    if cigar == "":
        return 0
    
    # This regular expression extracts all numbers from the cigar string as a list, e.g. 7H28M6S -> [7, 28, 6]
    cigar_list = re.findall(r'\d+', cigar)
    # Turn all those "string-numbers" to integers
    cigar_list = (int(num) for num in cigar_list)
    # Sum them up and return
    return sum(cigar_list)

def check_existence_of_seq(pair, pair_type):
    
    no_match = True
    for pair_already in cigar_matches[insertion][pair_type]:
        if pair_already[2] == pair[2]:
            no_match = False
            break
    if no_match:
        return True
    else:
        return False

#### 2nd layer ####
complementary_nucl = {"A": "T", "C": "G", "G": "C", "T": "A", "N": "N"}
# Iterate over all pairs of start- and end matches (may include synthetic matches in those pairs)
for insertion in node_matches.keys():
    # For best start matches
    best_cigar_start = -1
    # For best end matches
    best_cigar_end = -1
    # For best pairs (only used when no synthetic nodes were generated from previous layer)
    best_cigar_sum = -1
    # Initialize for every insertion a new/empty list, which will contain the filtered pairs from "node_matches"
    cigar_matches[insertion] = {"Complete": [], "Start": [], "End": []}
    
    for pair in node_matches[insertion]:
        
        # Get corrresponding start- and end match of pair
        start_match = pair[0]
        end_match = pair[1]
        
        # Get cigar strings
        start_cigar = start_match[4]
        end_cigar = end_match[4]
        
        # Get strand
        alg_type = start_match[3]
        
        # Get the start positions of the matching sequence (-1 because the SAM-files positions start by 1 and not 0)
        start_pos = start_match[2] - 1
        end_pos = end_match[2] - 1
        
        # Get corresponding node sequence (both matches have the same node by now!)
        node_seq = nodes_seqs[start_match[0]]
        
        # Compute end of assembled sequence
        seq_length = get_length_of_consensus(end_cigar)
        
        # Add this length to the end position to get the correct position
        end_pos_adj = end_pos+seq_length
        
        # Compute current length (main filter criteria for this layer)
        current_length = abs(end_pos_adj-start_pos)
        
        # If deletion is too long, discard it by skipping it in the loop
        if current_length > max_size:
            continue
        
        # If ciriteria from above is fullfilled, get assembled seq
        assembled_seq = node_seq[start_pos:end_pos_adj]
        # If the pair is on the reverse strand, make it a forward strand sequence by: reversing and complementing the sequence
        if alg_type == "Reverse":
            assembled_seq_rev = assembled_seq[::-1]
            assembled_seq_comp = ""
            for nucl in assembled_seq_rev:
                assembled_seq_comp += complementary_nucl[nucl]
            assembled_seq = assembled_seq_comp
        pair.append(assembled_seq)
        
        # Calculate the number of matching nucleotides of the cigar strings
        matches_num_start = get_matching_number(start_cigar)
        if matches_num_start == -1:
            continue
        matches_num_end = get_matching_number(end_cigar)
        if matches_num_end == -1:
            continue
        
        # For pairs with two "true" matches in the sam node
        if start_cigar != "" and end_cigar != "":
            # Calculate the sum of the two matches
            sum_num_matches = matches_num_start + matches_num_end
            # If this sum of the current pair is better than the best one observed so far, replace the "old" pair by the current pair/matches
            if sum_num_matches > best_cigar_sum:
                best_cigar_sum = sum_num_matches
                # Remove all stored matches, since we found a better one (Overwrite with the new list containing only the new, better pair)
                cigar_matches[insertion]["Complete"] = [pair]
            # If this mean/sum of the current pair is equally good to the best one observed so far, simply add it to the filtered pairs
            elif sum_num_matches == best_cigar_sum:
                if check_existence_of_seq(pair, "Complete"):
                    cigar_matches[insertion]["Complete"].append(pair)
        
        # For pairs with a synthetic end match
        elif start_cigar != "":
            # If the number of matching nucleotides at the start position of the current pair is better than the best one observed so far, replace the "old" pair by the current pair/matches
            if matches_num_start > best_cigar_start:
                best_cigar_start = matches_num_start
                # Remove all stored matches, since we found a better one (Overwrite with the new list containing only the new, better pair)
                cigar_matches[insertion]["Start"] = [pair]
            # If this mean/sum of the current pair is equally good to the best one observed so far, simply add it to the filtered pairs
            elif matches_num_start == best_cigar_start:
                if check_existence_of_seq(pair, "Start"):
                    cigar_matches[insertion]["Start"].append(pair)
        
        # For pairs with a synthetic start match
        elif end_cigar != "":
            # If the number of matching nucleotides at the end position of the current pair is better than the best one observed so far, replace the "old" pair by the current pair/matches
            if matches_num_end > best_cigar_end:
                best_cigar_end = matches_num_end
                # Remove all stored matches, since we found a better one (Overwrite with the new list containing only the new, better pair)
                cigar_matches[insertion]["End"] = [pair]
            # If this mean/sum of the current pair is equally good to the best one observed so far, simply add it to the filtered pairs
            elif matches_num_end == best_cigar_end:
                if check_existence_of_seq(pair, "End"):
                    cigar_matches[insertion]["End"].append(pair)


"""
#### 3rd layer & 4th layer ####

# Iterate over all pairs of start- and end matches (may include synthetic matches in those pairs), which resulted from the filtering steps of layer 2
for insertion in cigar_matches.keys():
    longest_seq = -1
    # Initialize for every insertion a new/empty list, which will contain the filtered pairs from "cigar_matches"
    length_matches[insertion] = []
    
    for match in cigar_matches[insertion]:
        
        # Get corrresponding start- and end match of pair
        start_match = match[0]
        end_match = match[1]
        
        # Get the start positions of the matching sequence (-1 because the SAM-files positions start by 1 and not 0)
        start_pos = start_match[2] - 1
        end_pos = end_match[2] - 1
        
        # Get strand
        alg_type = start_match[3]
        
        # Get corresponding node sequence (both matches have the same node by now!)
        node_seq = nodes_seqs[start_match[0]]
        # Get cigar string of end match, since we need the length of the end consensus sequence
        end_cigar = end_match[4]
        
        # Compute end of assembled sequence
        seq_length = get_length_of_consensus(end_cigar)
        
        # Add this length to the end position to get the correct position
        end_pos_adj = end_pos+seq_length
        
        # Compute current length (main filter criteria for this layer)
        current_length = abs(end_pos_adj-start_pos)
        
        # Check if the distance between start- and end match (so the length of the potential assembled sequence) is too long (mainly relevant for pairs with synthetic matches)
        # Check if this sequence is not shorter (so longer or equally long) than the longest permitted sequence observed so far
        if current_length > max_size or current_length < longest_seq:
            continue
        
        # If ciriterias from above are fullfilled, get assembled seq
        assembled_seq = node_seq[start_pos:end_pos_adj]
        # If the pair is on the reverse strand, make it a forward strand sequence by: reversing and complementing the sequence
        if alg_type == "Reverse":
            assembled_seq_rev = assembled_seq[::-1]
            assembled_seq_comp = ""
            for nucl in assembled_seq_rev:
                assembled_seq_comp += complementary_nucl[nucl]
            assembled_seq = assembled_seq_comp
        match.append(assembled_seq)
        
        # If the pair has a longer assembled sequence, replace the best one observed so far by it
        if current_length > longest_seq:
            length_matches[insertion] = [match]
            longest_seq = current_length
        # If it is equally long to the best one observed so far, add it, but only if the sequence differs (the pairs aren't of interest, just their sequence -> We don't want the same sequence several times in the output file!)
        elif current_length == longest_seq:
            no_match = True
            for match_already in length_matches[insertion]:
                if match_already[2] == match[2]:
                    no_match = False
                    break
            if no_match:
                length_matches[insertion].append(match)
#print(length_matches)
"""
# Write the best pair(s) into the output file
with open(output_path, "w") as file:
    # Iterate over all insertions
    for insertion in cigar_matches.keys():
        # Iterate over complete and partial pairs or matches
        for pair_type in ["Complete", "Start", "End"]:
            for pair in cigar_matches[insertion][pair_type]:
                file.write(f">INSERTION:{insertion}|")
                
                # If pair is orientated on forward strand, check if this pair is complete or partial (if partial, append warning)
                if pair[0][3] == "Forward":
                    # Check cigar string of start match
                    if pair[0][4] == "":
                        file.write("UPSTREAM MATCH:No upstream match was found|")
                    else:
                        file.write(f"UPSTREAM MATCH:{pair[0][4]}|")
                    # Check cigar string of end match    
                    if pair[1][4] == "":
                        file.write("DOWNSTREAM MATCH:No downstream match was found\n")
                    else:
                        file.write(f"DOWNSTREAM MATCH:{pair[1][4]}\n")
                # If pair is orientated on reverse strand, check if this pair is complete or partial (if partial, append warning)        
                elif pair[1][3] == "Reverse":
                    # Check cigar string of end match (We reversed and complemented this assembled sequence, so the end match would lead to an upstream warning and not to an downstream warning)
                    if pair[1][4] == "":
                        file.write("UPSTREAM MATCH:No upstream match was found|")
                    else:
                        file.write(f"UPSTREAM MATCH:{pair[1][4]}|")
                    # Vice versa
                    if pair[0][4] == "":
                        file.write("DOWNSTREAM MATCH:No downstream match was found\n")
                    else:
                        file.write(f"DOWNSTREAM MATCH:{pair[0][4]}\n")
                # Write sequence to file
                for i in range(0, len(pair[2]), 60):
                    file.write(f"{pair[2][i:i+60]}\n")
                        
                
                
                
        
            